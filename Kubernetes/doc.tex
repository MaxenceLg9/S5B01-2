\documentclass{report}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[table]{xcolor}
\usepackage[french]{babel}
\usepackage{titlesec}
\usepackage[a4paper]{geometry}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{babel}
\usepackage{minted}
\usepackage{fontspec}
\usepackage{tcolorbox}
\usepackage{hyperref}
\usepackage{titling}
\usepackage{enumitem}
\usepackage{fancyvrb}
\usepackage{tikz}
\usepackage{changepage}
\usepackage{tabularx}
\usepackage{float}
\usepackage{amsmath, amssymb}

\setmainfont{Calibri}



\setlist[itemize]{label=\large\textbullet}


\definecolor{azure}{rgb}{0.2, 0.7, 1.0}
\definecolor{bggray}{gray}{0.95}

\setlength{\parindent}{0pt}

\hypersetup{
	colorlinks=true,
	linkcolor=purple,
	filecolor=magenta,      
	urlcolor=blue,
	pdfborder={0 0 1}
}

\titleformat{\chapter}[block]
{\normalfont\LARGE\bfseries} % Style: large bold text
{\thechapter}                % Keep chapter number (remove if unwanted)
{1em}                        % Spacing between number and title
{}     

\urlstyle{same}

\geometry{width=18cm}
\geometry{a4paper}

\lstset{
	basicstyle=\ttfamily\small, % typewriter font
	keywordstyle=\color{blue}\bfseries, % keywords
	commentstyle=\color{green!50!black}\itshape, % comments
	stringstyle=\color{red}, % strings
	showstringspaces=false,
	numbers=none, % line numbers on the left
	backgroundcolor=\color{bggray},
	breaklines=true,
	frame=none,
	tabsize=4
}

\lstdefinelanguage{Rust}{
    keywords={fn, let, mut, if, else, match, impl, struct, enum, use, pub},
    sensitive=true,
    comment=[l]{//},
    morecomment=[s]{/*}{*/},
    morestring=[b]",
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
}

% Define a new environment "varblock" with 1 argument = label
\newenvironment{terminal}[1]{%
	\Verbatim[frame=none, numbers=none,label={#1}, breaklines, breakanywhere,tabsize=4,breaksymbol=, breakanywheresymbolpre=,backgroundcolor=bggray]%
}{%
	\endVerbatim
}


\renewcommand{\thechapter}{\Roman{chapter}}
\renewcommand{\thesection}{\thechapter.\Alph{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\alph{subsubsection}}


\pretitle{%
	\begin{center}
		\LARGE
		\includegraphics[width=6cm,height=2cm]{../../../../../../Format/logo-UT-site.png}\\[\bigskipamount]
	}
	\posttitle{\end{center}}

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{3} 

\title{\Huge{\bfseries S5.B.01 Phase 4\\Déploiement de services}}
\date{\today}
\author{Maxence Lagourgue}

\begin{document}
	
	\maketitle
	\tableofcontents
	
	\chapter{Introduction}
	
	\section{Outils}
	
	Dans cette partie, les outils utilisés seront:
	\begin{itemize}
	\item Rancher pour la gestion des clusters
	\item RKE2 pour la mise en œuvre Kubernetes des nœuds de travail
	\item k3s pour le cluster Rancher
	\item kubectl pour la gestion des ressources
	\item Helm pour la gestion des applications
	\end{itemize}
	
	Plus tard, si nous avons le temps, nous utiliserons Ansible pour automiser la chaîne de production Rancher.
	
	\section{Machines}
	
	Les machines utilisées au cours de ce projet seront:
	
	\begin{itemize}
	\item K8SA2 (k8s1) $\Longrightarrow$ k3s cluster + Rancher Server
	\item K8SB2 (k8s2) $\Longrightarrow$ RKE2 cluster + Master, Etcd, Worker Nodes
	\item K8SC2 (k8s3) $\Longrightarrow$ RKE2 cluster + Worker nodes + Backup
	\end{itemize}
	

	\chapter{Installation de Rancher dans un cluster k3s}
	
	Pour utiliser Rancher, plusieurs méthodes d'installation s'offrent à nous.
	L'une avec docker, l'autre en tant que noeud Kubernetes. 
	Les autres installations reposent sur l'utilisation d'un Cloud Provider ainsi que Terraform donc inutile dans notre cas.
	
	Exemple de tutorial: \href{https://blog.stephane-robert.info/docs/conteneurs/orchestrateurs/outils/rancher/}{Tutorial Rancher 2025}
	
	Faire le gitlab en tant qu'application kubernetes/rancher.
	
	
	\section{Installation de k3s}
	
	\begin{terminal}{Installation de k3s}
	curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION="v1.24.10+k3s1" sh -s - server --cluster-init
	\end{terminal}
	
	\subsection{Accès distant au cluster (Optionnel)}
	
	\verb*|<IP_OF_LINUX_MACHINE>| est l'IP de la machine distante sur laquelle se trouve le cluster.
	
	\begin{terminal}{}
	scp root@<IP_OF_LINUX_MACHINE>:/etc/rancher/k3s/k3s.yaml ~/.kube/config
	\end{terminal}

	\begin{terminal}{Modifier l'URL du serveur rancher}
	nano ~/.kube/config
	\end{terminal}
	
	\subsection{Installation d'helm}
	
	\begin{terminal}{}
	sudo apt-get install curl gpg apt-transport-https --yes
	
	curl -fsSL https://packages.buildkite.com/helm-linux/helm-debian/gpgkey | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
	
	echo "deb [signed-by=/usr/share/keyrings/helm.gpg] https://packages.buildkite.com/helm-linux/helm-debian/any/ any main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
	
	sudo apt-get update
	sudo apt-get install helm
	\end{terminal}
	
	\subsection{Installation de kubectl}
	
	\begin{terminal}{}
	sudo apt-get install -y apt-transport-https ca-certificates curl gnupg
	
	curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.34/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
	
	sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg
	
	echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.34/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
	sudo chmod 644 /etc/apt/sources.list.d/kubernetes.list
	
	sudo apt-get update
	sudo apt-get install -y kubectl
	\end{terminal}
	
	\subsection{Création d'un Déploiement Rancher}
	
	<Hostname> correspond au nom de domaine utilisé pour contacter le pod rancher.
	
	\begin{terminal}{Creation du pod Rancher avec Helm}
	export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
	

	
	kubectl create namespace cattle-system
	kubectl config set-context --current --namespace=cattle-system
	
	kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.19.2/cert-manager.crds.yaml
	
	helm repo add rancher-latest https://releases.rancher.com/server-charts/latest
	
	helm repo add jetstack https://charts.jetstack.io
	
	helm repo update
	
	helm install cert-manager jetstack/cert-manager \
	  --namespace cert-manager \
	  --create-namespace
	  
	helm install rancher rancher-latest/rancher \
	  --namespace cattle-system \
	  --set hostname=10.0.1.3.sslip.io \
	  --set replicas=1 \
	  --set bootstrapPassword=$iutinfo
	\end{terminal}
	
	Il faut maintenant attendre car l'installation nécessite quelques minutes.
	On peut vérifier avec \verb*|kubectl get pods -n cattle-system|
	
	Une fois fait, on se connecte à la page et on récupère le mot de passe:
	\begin{terminal}{}
	kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}{{"\n"}}'
	\end{terminal}
	
	On définit un nouveau mot de passe qui est \verb*|qJHiA@wwaagi46U|.
	
	\subsection{Pour arrêter/pauser Rancher}
	
	\begin{terminal}{}
	kubectl scale --replicas=0 deployment/rancher -n cattle-system
	\end{terminal}
	
	Cela permet d'arrêter temporairement le pod Rancher.
	
	\section{Réinitialisation du cluster}
	
	Pour revenir à l'état 0 du cluster, il est possible de:
	\begin{terminal}{}
	rm -rf /var/lib/rancher/k3s/server/db/etcd
	/usr/local/bin/k3s-killall.sh
	systemctl restart k3s.service
	\end{terminal}
	
	\chapter{Création d'un cluster}
	
	\section{Enrôlement de machines}
	
	Pour cela il faut aller dans la section \textbf{Clusters $\Longrightarrow$ <Cluster> $\Longrightarrow$ Registration}
	
	\begin{terminal}{}
	curl --insecure -fL https://10.0.1.3.sslip.io/system-agent-install.sh | sudo  sh -s - --server https://10.0.1.3.sslip.io --label 'cattle.io/os=linux' --token wq74n2j9rxj2th5t6xjf5b8dnjkrn6bbss6brnnzxx6tvwkj5m7xbg --ca-checksum 60da38d3a88ecb90961987a65f52b63d1ee2aa62b2e0ab6d4710ba1ba00b6ded --etcd --controlplane --worker --internal-address 10.0.1.4,2001:db8:1:1::4 --node-name Main
	\end{terminal}
	\chapter{Méthodologie de déploiement des applications}

Une fois l’infrastructure Kubernetes mise en place et le cluster RKE2
correctement enrôlé dans Rancher, la phase suivante du projet consiste
à déployer les services applicatifs.
Ces services correspondent à une application composée
d’un serveur web et d’une base de données.

Le déploiement applicatif ne s’effectue pas sur le cluster k3s
hébergeant Rancher, mais exclusivement sur le cluster RKE2,
composé des machines K8SB2 et K8SC2.
Le cluster k3s joue uniquement un rôle de support pour la gestion
et l’administration via Rancher.

\section{Principe général du déploiement}

Le déploiement des applications repose sur l’utilisation
de fichiers de configuration Kubernetes (manifests YAML).
Ces fichiers décrivent l’état désiré du cluster,
notamment le nombre de réplicas, les images utilisées,
ainsi que les règles de communication entre les composants.

Rancher est utilisé comme interface de gestion afin d’appliquer
ces fichiers YAML sur le cluster RKE2.
Techniquement, Rancher transmet les configurations
au serveur API Kubernetes du cluster,
ce qui est équivalent à l’exécution de la commande
\texttt{kubectl apply -f}.

\section{Organisation des ressources Kubernetes}

Afin de structurer correctement le déploiement,
un namespace dédié à l’application est créé.
Ce namespace permet d’isoler les ressources applicatives
du reste du cluster et d’améliorer la lisibilité de l’infrastructure.

L’application est ensuite découpée en deux composants distincts :
\begin{itemize}
    \item un composant serveur web,
    \item un composant base de données.
\end{itemize}

Chaque composant est déployé à l’aide :
\begin{itemize}
    \item d’un Deployment Kubernetes, chargé de gérer les pods,
    \item d’un Service Kubernetes, chargé d’assurer la communication réseau.
\end{itemize}

\section{Déploiement de la base de données}

La base de données est déployée en premier,
car elle constitue une dépendance pour le serveur web.
Un Deployment est utilisé pour définir l’image de la base de données
ainsi que les variables d’environnement nécessaires à son fonctionnement.

Un Service de type \texttt{ClusterIP} est associé à ce Deployment.
Ce Service fournit une adresse réseau stable au sein du cluster,
permettant au serveur web de communiquer avec la base de données
sans dépendre des adresses IP des pods.

\section{Déploiement du serveur web}

Le serveur web est ensuite déployé sous la forme d’un Deployment Kubernetes.
Le nombre de réplicas est défini afin de permettre la haute disponibilité
du service et la répartition de la charge sur plusieurs nœuds du cluster.

Le serveur web accède à la base de données
en utilisant le nom du Service Kubernetes associé à celle-ci.
Cette méthode garantit une communication fiable,
même en cas de redémarrage ou de déplacement des pods.

Un Service de type \texttt{NodePort} ou \texttt{LoadBalancer}
est utilisé pour exposer le serveur web
et permettre l’accès à l’application depuis l’extérieur du cluster.

\section{Supervision et validation du déploiement}

Rancher permet de superviser l’ensemble du déploiement applicatif.
Il est possible de visualiser l’état des pods,
le nombre de réplicas actifs,
ainsi que les logs des différents conteneurs.

Cette supervision facilite la validation du bon fonctionnement
des services déployés et permet d’illustrer
le comportement automatique de Kubernetes,
notamment en cas de suppression ou de redémarrage d’un pod.

	
\end{document}
